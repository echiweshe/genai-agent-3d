model: llama3.2:latest
parameters:
  max_tokens: 2048
  temperature: 0.7
provider: ollama
providers:
  ollama:
    base_url: http://127.0.0.1:11434
type: local
